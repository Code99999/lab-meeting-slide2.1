<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lab Meeting: Text-to-Image Bias Analysis</title>
    <meta name="description" content="Research presentation on text-to-image bias analysis framework and methodology">
    <meta name="author" content="Stanford Lab Research Team">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: #0f0f23;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
            position: relative;
            overflow-x: hidden;
        }

        body::before {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            background: 
                radial-gradient(circle at 20% 50%, rgba(120, 119, 198, 0.3) 0%, transparent 50%),
                radial-gradient(circle at 80% 20%, rgba(255, 119, 198, 0.15) 0%, transparent 50%),
                radial-gradient(circle at 40% 80%, rgba(120, 219, 255, 0.2) 0%, transparent 50%);
            animation: float 20s ease-in-out infinite;
            z-index: -1;
        }

        @keyframes float {
            0%, 100% { transform: translate(0px, 0px) rotate(0deg); }
            33% { transform: translate(30px, -30px) rotate(2deg); }
            66% { transform: translate(-20px, 20px) rotate(-2deg); }
        }

        .slide {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(20px);
            border-radius: 24px;
            padding: 48px;
            max-width: 1400px;
            width: 100%;
            border: 1px solid rgba(255, 255, 255, 0.1);
            position: relative;
            animation: slideInUp 1.2s cubic-bezier(0.4, 0, 0.2, 1);
            box-shadow: 
                0 32px 64px rgba(0, 0, 0, 0.3),
                inset 0 1px 0 rgba(255, 255, 255, 0.1);
        }

        @keyframes slideInUp {
            from {
                opacity: 0;
                transform: translateY(60px) scale(0.95);
            }
            to {
                opacity: 1;
                transform: translateY(0) scale(1);
            }
        }

        .header {
            text-align: center;
            margin-bottom: 48px;
            padding-bottom: 24px;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            animation: fadeInDown 1s ease-out 0.3s both;
        }

        @keyframes fadeInDown {
            from {
                opacity: 0;
                transform: translateY(-30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .title {
            font-size: 3.2rem;
            font-weight: 700;
            color: #ffffff;
            margin-bottom: 12px;
            background: linear-gradient(135deg, #ff7eb3, #ff758c, #7c4dff, #00b4db);
            background-size: 300% 300%;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            animation: gradientShift 8s ease-in-out infinite;
            line-height: 1.1;
            letter-spacing: -0.02em;
        }

        @keyframes gradientShift {
            0%, 100% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
        }

        .subtitle {
            font-size: 1.4rem;
            color: rgba(255, 255, 255, 0.7);
            font-weight: 400;
            margin-bottom: 24px;
        }

        .objective {
            background: linear-gradient(135deg, rgba(0, 180, 219, 0.1), rgba(124, 77, 255, 0.1));
            border: 1px solid rgba(0, 180, 219, 0.3);
            padding: 32px;
            border-radius: 16px;
            margin-bottom: 40px;
            position: relative;
            overflow: hidden;
            animation: slideInLeft 1s ease-out 0.5s both;
        }

        .objective::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 2px;
            background: linear-gradient(90deg, transparent, rgba(0, 180, 219, 0.8), transparent);
            animation: shimmer 3s ease-in-out infinite;
        }

        @keyframes shimmer {
            0% { left: -100%; }
            100% { left: 100%; }
        }

        @keyframes slideInLeft {
            from {
                opacity: 0;
                transform: translateX(-40px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        .objective-title {
            font-size: 1.5rem;
            font-weight: 600;
            color: #00b4db;
            margin-bottom: 16px;
            display: flex;
            align-items: center;
            gap: 12px;
        }

        .objective-text {
            color: rgba(255, 255, 255, 0.85);
            line-height: 1.7;
            font-size: 1.05rem;
        }

        .methodology {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 32px;
            margin-bottom: 40px;
        }

        .tier {
            background: rgba(255, 255, 255, 0.03);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 32px;
            position: relative;
            overflow: hidden;
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            animation: slideInRight 1s ease-out 0.7s both;
        }

        .tier:nth-child(1) {
            animation-delay: 0.7s;
        }

        .tier:nth-child(2) {
            animation-delay: 0.9s;
        }

        @keyframes slideInRight {
            from {
                opacity: 0;
                transform: translateX(40px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        .tier::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: linear-gradient(135deg, rgba(255, 126, 179, 0.1), rgba(124, 77, 255, 0.1));
            opacity: 0;
            transition: opacity 0.4s ease;
            border-radius: 20px;
        }

        .tier:hover {
            transform: translateY(-8px) scale(1.02);
            border-color: rgba(255, 126, 179, 0.4);
            box-shadow: 
                0 20px 40px rgba(255, 126, 179, 0.1),
                0 0 0 1px rgba(255, 126, 179, 0.2);
        }

        .tier:hover::before {
            opacity: 1;
        }

        .tier-title {
            font-size: 1.6rem;
            font-weight: 600;
            color: #ffffff;
            margin-bottom: 24px;
            display: flex;
            align-items: center;
            gap: 12px;
        }

        .tier-icon {
            width: 40px;
            height: 40px;
            border-radius: 12px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            color: white;
            font-size: 1rem;
            position: relative;
            overflow: hidden;
        }

        .tier1-icon {
            background: linear-gradient(135deg, #00b4db, #0083b0);
        }

        .tier2-icon {
            background: linear-gradient(135deg, #ff7eb3, #ff758c);
        }

        .tier-icon::after {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.4), transparent);
            transition: left 0.5s ease;
        }

        .tier:hover .tier-icon::after {
            left: 100%;
        }

        .method {
            margin-bottom: 20px;
            padding: 20px;
            background: rgba(255, 255, 255, 0.02);
            border-radius: 12px;
            border-left: 3px solid transparent;
            border-image: linear-gradient(135deg, #ff7eb3, #7c4dff) 1;
            transition: all 0.3s ease;
            position: relative;
        }

        .method:hover {
            background: rgba(255, 255, 255, 0.05);
            transform: translateX(4px);
        }

        .method-name {
            font-weight: 600;
            color: #ffffff;
            margin-bottom: 8px;
            font-size: 1.1rem;
        }

        .method-desc {
            color: rgba(255, 255, 255, 0.7);
            font-size: 0.95rem;
            line-height: 1.6;
        }

        .method-desc strong {
            color: rgba(255, 255, 255, 0.9);
        }

        .status-section {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 32px;
            margin-top: 40px;
        }

        .status-card {
            background: linear-gradient(135deg, rgba(255, 126, 179, 0.1), rgba(255, 117, 140, 0.1));
            border: 1px solid rgba(255, 126, 179, 0.2);
            border-radius: 16px;
            padding: 32px;
            text-align: left;
            position: relative;
            overflow: hidden;
            animation: slideInUp 1s ease-out 1.1s both;
        }

        .next-steps {
            background: linear-gradient(135deg, rgba(124, 77, 255, 0.1), rgba(0, 180, 219, 0.1));
            border: 1px solid rgba(124, 77, 255, 0.2);
            border-radius: 16px;
            padding: 32px;
            animation: slideInUp 1s ease-out 1.3s both;
        }

        .status-title {
            font-size: 1.4rem;
            font-weight: 600;
            color: #ff7eb3;
            margin-bottom: 20px;
        }

        .next-steps-title {
            font-size: 1.4rem;
            font-weight: 600;
            color: #7c4dff;
            margin-bottom: 20px;
        }

        .status-text {
            color: rgba(255, 255, 255, 0.8);
            line-height: 1.6;
            font-size: 1rem;
        }

        .status-text strong {
            color: rgba(255, 255, 255, 0.95);
        }

        .progress-bar {
            width: 100%;
            height: 6px;
            background: rgba(255, 126, 179, 0.2);
            border-radius: 3px;
            margin-top: 20px;
            overflow: hidden;
            position: relative;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #ff7eb3, #ff758c);
            width: 0%;
            border-radius: 3px;
            animation: progressFill 2s ease-out 2s forwards;
            position: relative;
        }

        .progress-fill::after {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.6), transparent);
            animation: progressShine 1.5s ease-in-out 3.5s infinite;
        }

        @keyframes progressFill {
            to { width: 85%; }
        }

        @keyframes progressShine {
            0% { left: -100%; }
            100% { left: 100%; }
        }

        .step {
            display: flex;
            align-items: center;
            gap: 16px;
            margin-bottom: 16px;
            color: rgba(255, 255, 255, 0.8);
            transition: all 0.3s ease;
            padding: 8px 0;
            opacity: 0;
            animation: stepFadeIn 0.5s ease-out forwards;
        }

        .step:nth-child(2) { animation-delay: 1.5s; }
        .step:nth-child(3) { animation-delay: 1.7s; }
        .step:nth-child(4) { animation-delay: 1.9s; }
        .step:nth-child(5) { animation-delay: 2.1s; }

        @keyframes stepFadeIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .step:hover {
            transform: translateX(8px);
            color: rgba(255, 255, 255, 0.95);
        }

        .step-number {
            background: linear-gradient(135deg, #7c4dff, #5c6bc0);
            color: white;
            width: 32px;
            height: 32px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.9rem;
            font-weight: bold;
            position: relative;
            overflow: hidden;
            flex-shrink: 0;
        }

        .step-number::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.3), transparent);
            transition: left 0.5s ease;
        }

        .step:hover .step-number::before {
            left: 100%;
        }

        /* Particle animation */
        .slide::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-image: 
                radial-gradient(circle at 1px 1px, rgba(255, 255, 255, 0.15) 1px, transparent 0);
            background-size: 50px 50px;
            opacity: 0.3;
            animation: particleMove 20s linear infinite;
            pointer-events: none;
        }

        @keyframes particleMove {
            0% { background-position: 0 0; }
            100% { background-position: 50px 50px; }
        }

        @media (max-width: 1024px) {
            .methodology {
                grid-template-columns: 1fr;
            }
            
            .status-section {
                grid-template-columns: 1fr;
            }
            
            .title {
                font-size: 2.5rem;
            }

            .slide {
                padding: 32px;
            }
        }

        @media (max-width: 768px) {
            .title {
                font-size: 2rem;
            }

            .slide {
                padding: 24px;
            }

            .methodology {
                gap: 24px;
            }

            .status-section {
                gap: 24px;
            }
        }
    </style>
</head>
<body>
    <div class="slide">
        <div class="header">
            <h1 class="title">Text-to-Image Bias Analysis</h1>
            <p class="subtitle">Finding Hidden Biases in AI Image Generation</p>
        </div>

        <div class="objective">
            <h2 class="objective-title">🎯 What We're Trying to Figure Out</h2>
            <p class="objective-text">
                <strong>The Problem:</strong> When you ask DALL-E to draw "a doctor," it usually shows a white man in a lab coat. We want to build a system that catches these models when they add their own assumptions to neutral prompts.<br><br>
                <strong>Our Method:</strong> Instead of just guessing at bias, we're documenting it. Some platforms show you their "improved" version of your prompt (like ChatGPT), while others hide what they're doing. We'll use both direct evidence and some detective work to figure out what's happening behind the scenes.<br><br>
                <strong>Why This Matters:</strong> These models are being used everywhere. If we can measure exactly how and where bias shows up, we can actually fix it instead of just saying "AI is biased."
            </p>
        </div>

        <div class="methodology">
            <div class="tier">
                <h3 class="tier-title">
                    <span class="tier-icon tier1-icon">T1</span>
                    Direct Evidence (The Easy Cases)
                </h3>
                
                <div class="method">
                    <div class="method-name">ChatGPT/DALL-E (Stanford AI Playground)</div>
                    <div class="method-desc">
                        <strong>What we get:</strong> Your prompt → ChatGPT's "improved" prompt → The image<br>
                        <strong>How we do it:</strong> Automated scripts (no manual clicking through hundreds of prompts)<br>
                        <strong>The payoff:</strong> We can see exactly where ChatGPT decides to add details you never asked for
                    </div>
                </div>
                
                <div class="method">
                    <div class="method-name">Stable Diffusion (Local Setup)</div>
                    <div class="method-desc">
                        <strong>The process:</strong> Your prompt → Generated image → CLIP analyzes what it thinks it made<br>
                        <strong>Our tool:</strong> The "Interrogate CLIP" feature most people ignore<br>
                        <strong>What we learn:</strong> How much the model's understanding differs from your actual words
                    </div>
                </div>
            </div>

            <div class="tier">
                <h3 class="tier-title">
                    <span class="tier-icon tier2-icon">T2</span>
                    Reverse Engineering
                </h3>
                
                <div class="method">
                    <div class="method-name">External CLIP Analysis</div>
                    <div class="method-desc">
                        <strong>Target platforms:</strong> Midjourney, Gemini, DeepAI (the ones that don't show their work)<br>
                        <strong>The process:</strong> Generate images, feed them to CLIP tools, see what prompts CLIP thinks would create these images<br>
                        <strong>The reveal:</strong> Compare the reconstructed prompts to your original—spot the hidden assumptions
                    </div>
                </div>
                
                <div class="method">
                    <div class="method-name">Multiple Model Cross-Check</div>
                    <div class="method-desc">
                        <strong>Our tools:</strong> BLIP-2, InstructBLIP, and other image-to-text models<br>
                        <strong>Why multiple models:</strong> If three different systems all see the same bias in an image, it's probably real<br>
                        <strong>Bonus:</strong> Catch biases that are so common even CLIP doesn't notice them
                    </div>
                </div>
                
                <div class="method">
                    <div class="method-name">Prompt Reconstruction</div>
                    <div class="method-desc">
                        <strong>The experiment:</strong> Start with "a teacher," generate image, then try to recreate it with specific prompts<br>
                        <strong>The discovery:</strong> "To recreate this I need to add 'female,' 'elementary school,' 'apple on desk'..."<br>
                        <strong>The insight:</strong> Map out all the hidden assumptions the model added to your simple request
                    </div>
                </div>
            </div>
        </div>

        <div class="status-section">
            <div class="status-card">
                <h3 class="status-title">📊 Current Status</h3>
                <p class="status-text">
                    <strong>Framework:</strong> Built and ready to use<br>
                    <strong>Technical setup:</strong> Scripts written, platform access secured<br>
                    <strong>Test data:</strong> Neutral prompt sets prepared (professions, activities, general scenarios)<br>
                    <strong>Analysis tools:</strong> CLIP tools tested, BLIP models configured and ready
                </p>
                <div class="progress-bar">
                    <div class="progress-fill"></div>
                </div>
            </div>

            <div class="next-steps">
                <h3 class="next-steps-title">🔬 Analysis Pipeline</h3>
                <div class="step">
                    <span class="step-number">1</span>
                    <span><strong>Automated Detection:</strong> Use FairFace and DeepFace to automatically identify race and gender in generated images</span>
                </div>
                <div class="step">
                    <span class="step-number">2</span>
                    <span><strong>Human Evaluation:</strong> Custom website for people to rate how biased each image looks</span>
                </div>
                <div class="step">
                    <span class="step-number">3</span>
                    <span><strong>Cross-Validation:</strong> Compare computer results with human ratings to catch subtle biases</span>
                </div>
                <div class="step">
                    <span class="step-number">4</span>
                    <span><strong>Pattern Analysis:</strong> Find connections between prompt changes and demographic shifts in the results</span>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
